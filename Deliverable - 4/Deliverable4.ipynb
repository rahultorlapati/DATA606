{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm \n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5f0feb3e7f4492a1bffacf5366660d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "original_fake_paths = []\n",
    "\n",
    "for dirname, _, filenames in tqdm(os.walk('/Users/rahultorlapati/Downloads/Semester 4/DATA 606/Datasets/untitled folder/fake')):\n",
    "    for filename in filenames:\n",
    "        original_fake_paths.append([os.path.join(dirname, filename)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10001"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(original_fake_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fake_paths, test_fake_paths = train_test_split(original_fake_paths, test_size=2000, random_state=2019)\n",
    "\n",
    "fake_train_df = pd.DataFrame(train_fake_paths, columns=['filename'])\n",
    "fake_train_df['class'] = 'FAKE'\n",
    "\n",
    "fake_test_df = pd.DataFrame(test_fake_paths, columns=['filename'])\n",
    "fake_test_df['class'] = 'FAKE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc358202184649198c82c2a5af083dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "original_real_paths = []\n",
    "\n",
    "for dirname, _, filenames in tqdm(os.walk('/Users/rahultorlapati/Downloads/Semester 4/DATA 606/Datasets/untitled folder/real')):\n",
    "    for filename in filenames:\n",
    "        original_real_paths.append([os.path.join(dirname, filename)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_real_paths = original_real_paths[0:10001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_real_paths, test_real_paths = train_test_split(original_real_paths, test_size=2000, random_state=2019)\n",
    "\n",
    "real_train_df = pd.DataFrame(train_real_paths, columns=['filename'])\n",
    "real_train_df['class'] = 'REAL'\n",
    "\n",
    "real_test_df = pd.DataFrame(test_real_paths, columns=['filename'])\n",
    "real_test_df['class'] = 'REAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([real_train_df, fake_train_df])\n",
    "test_df = pd.concat([real_test_df, fake_test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16001 validated image filenames belonging to 2 classes.\n",
      "Found 4000 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_gen = datagen.flow_from_dataframe(\n",
    "    df,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_dataframe(\n",
    "    df,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "\n",
    "model = tensorflow.keras.Sequential()\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(224,224,3)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 220, 220, 32)      18464     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1548800)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 3097602   \n",
      "=================================================================\n",
      "Total params: 3,117,858\n",
      "Trainable params: 3,117,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-52e97f15aac7>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/7\n",
      "251/251 [==============================] - 710s 3s/step - loss: 0.2197 - accuracy: 0.9721 - val_loss: 0.0525 - val_accuracy: 0.9815\n",
      "Epoch 2/7\n",
      "251/251 [==============================] - 718s 3s/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0082 - val_accuracy: 0.9977\n",
      "Epoch 3/7\n",
      "251/251 [==============================] - 763s 3s/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0068 - val_accuracy: 0.9977\n",
      "Epoch 4/7\n",
      "251/251 [==============================] - 802s 3s/step - loss: 9.2370e-05 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9977\n",
      "Epoch 5/7\n",
      "251/251 [==============================] - 776s 3s/step - loss: 1.8363e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
      "Epoch 6/7\n",
      "251/251 [==============================] - 795s 3s/step - loss: 1.0603e-05 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9985\n",
      "Epoch 7/7\n",
      "251/251 [==============================] - 772s 3s/step - loss: 7.5399e-06 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9985\n"
     ]
    }
   ],
   "source": [
    "train_history_step1 = model.fit_generator(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    steps_per_epoch=len(train_gen),\n",
    "    validation_steps=len(val_gen),\n",
    "    epochs = 7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tensorflow.keras.Sequential()\n",
    "model1.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(224,224,3)))\n",
    "model1.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Dropout(0.25))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 220, 220, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 110, 110, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 110, 110, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 774400)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               99123328  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 99,142,978\n",
      "Trainable params: 99,142,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "251/251 [==============================] - 746s 3s/step - loss: 0.4098 - accuracy: 0.9687 - val_loss: 0.0179 - val_accuracy: 0.9930\n",
      "Epoch 2/7\n",
      "251/251 [==============================] - 750s 3s/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0143 - val_accuracy: 0.9960\n",
      "Epoch 3/7\n",
      "251/251 [==============================] - 671s 3s/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0024 - val_accuracy: 0.9987\n",
      "Epoch 4/7\n",
      "251/251 [==============================] - 716s 3s/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0080 - val_accuracy: 0.9973\n",
      "Epoch 5/7\n",
      "251/251 [==============================] - 739s 3s/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0096 - val_accuracy: 0.9962\n",
      "Epoch 6/7\n",
      "251/251 [==============================] - 723s 3s/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0185 - val_accuracy: 0.9933\n",
      "Epoch 7/7\n",
      "251/251 [==============================] - 730s 3s/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0051 - val_accuracy: 0.9977\n"
     ]
    }
   ],
   "source": [
    "train_history_step2 = model1.fit_generator(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    steps_per_epoch=len(train_gen),\n",
    "    validation_steps=len(val_gen),\n",
    "    epochs=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = DenseNet121(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224,224,3)\n",
    ")\n",
    "\n",
    "for layer in densenet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(densenet):\n",
    "    model = tensorflow.keras.Sequential()\n",
    "    model.add(densenet)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(lr=0.0005),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet121 (Model)          (None, 7, 7, 1024)        7037504   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 7,305,281\n",
      "Trainable params: 265,217\n",
      "Non-trainable params: 7,040,064\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = build_model(densenet)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "251/251 [==============================] - 869s 3s/step - loss: 0.0672 - accuracy: 0.9743 - val_loss: 0.0094 - val_accuracy: 0.9987\n",
      "Epoch 2/7\n",
      "251/251 [==============================] - 840s 3s/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.0020 - val_accuracy: 0.9992\n",
      "Epoch 3/7\n",
      "251/251 [==============================] - 829s 3s/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 9.3182e-04 - val_accuracy: 0.9998\n",
      "Epoch 4/7\n",
      "251/251 [==============================] - 823s 3s/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 2.6615e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/7\n",
      "251/251 [==============================] - 829s 3s/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 3.0940e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/7\n",
      "251/251 [==============================] - 829s 3s/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 2.0069e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/7\n",
      "251/251 [==============================] - 831s 3s/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 2.5472e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "train_history_step3 = model2.fit_generator(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    steps_per_epoch=len(train_gen),\n",
    "    validation_steps=len(val_gen),\n",
    "    epochs=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = keras.applications.resnet50.ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224,224,3)\n",
    ")\n",
    "\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(resnet):\n",
    "    model = tensorflow.keras.Sequential()\n",
    "    model.add(resnet)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(lr=0.0005),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 24,121,729\n",
      "Trainable params: 529,409\n",
      "Non-trainable params: 23,592,320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = build_model(resnet)\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "251/251 [==============================] - 577s 2s/step - loss: 0.3237 - accuracy: 0.8700 - val_loss: 1.1707 - val_accuracy: 0.0428\n",
      "Epoch 2/7\n",
      "251/251 [==============================] - 579s 2s/step - loss: 0.2130 - accuracy: 0.9184 - val_loss: 0.5699 - val_accuracy: 0.6975\n",
      "Epoch 3/7\n",
      "251/251 [==============================] - 575s 2s/step - loss: 0.1944 - accuracy: 0.9236 - val_loss: 0.1792 - val_accuracy: 0.9335\n",
      "Epoch 4/7\n",
      "251/251 [==============================] - 578s 2s/step - loss: 0.1717 - accuracy: 0.9317 - val_loss: 0.1660 - val_accuracy: 0.9327\n",
      "Epoch 5/7\n",
      "251/251 [==============================] - 574s 2s/step - loss: 0.1619 - accuracy: 0.9383 - val_loss: 0.1199 - val_accuracy: 0.9525\n",
      "Epoch 6/7\n",
      "251/251 [==============================] - 581s 2s/step - loss: 0.1474 - accuracy: 0.9433 - val_loss: 0.1372 - val_accuracy: 0.9442\n",
      "Epoch 7/7\n",
      "251/251 [==============================] - 578s 2s/step - loss: 0.1600 - accuracy: 0.9391 - val_loss: 0.1152 - val_accuracy: 0.9525\n"
     ]
    }
   ],
   "source": [
    "train_history_step4 = model3.fit_generator(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    steps_per_epoch=len(train_gen),\n",
    "    validation_steps=len(val_gen),\n",
    "    epochs=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception = tensorflow.keras.applications.Xception(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224,224,3)\n",
    ")\n",
    "\n",
    "for layer in xception.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(xception):\n",
    "    model = tensorflow.keras.Sequential()\n",
    "    model.add(xception)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(lr=0.0005),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 7, 7, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,879,913\n",
      "Trainable params: 10,241\n",
      "Non-trainable params: 20,869,672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = build_model(xception)\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-c6c5f0b04490>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/7\n",
      "251/251 [==============================] - 535s 2s/step - loss: 0.2106 - accuracy: 0.9149 - val_loss: 0.1659 - val_accuracy: 0.9655\n",
      "Epoch 2/7\n",
      "251/251 [==============================] - 521s 2s/step - loss: 0.0683 - accuracy: 0.9759 - val_loss: 0.0316 - val_accuracy: 0.9930\n",
      "Epoch 3/7\n",
      "251/251 [==============================] - 518s 2s/step - loss: 0.0450 - accuracy: 0.9844 - val_loss: 0.0170 - val_accuracy: 0.9952\n",
      "Epoch 4/7\n",
      "251/251 [==============================] - 518s 2s/step - loss: 0.0391 - accuracy: 0.9869 - val_loss: 0.0119 - val_accuracy: 0.9973\n",
      "Epoch 5/7\n",
      "251/251 [==============================] - 546s 2s/step - loss: 0.0338 - accuracy: 0.9882 - val_loss: 0.0111 - val_accuracy: 0.9962\n",
      "Epoch 6/7\n",
      "251/251 [==============================] - 792s 3s/step - loss: 0.0328 - accuracy: 0.9881 - val_loss: 0.0091 - val_accuracy: 0.9970\n",
      "Epoch 7/7\n",
      "251/251 [==============================] - 564s 2s/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 0.0084 - val_accuracy: 0.9980\n"
     ]
    }
   ],
   "source": [
    "train_history_step5 = model4.fit_generator(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    steps_per_epoch=len(train_gen),\n",
    "    validation_steps=len(val_gen),\n",
    "    epochs=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_history_step5.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.16594697535037994,\n",
       " 0.031580112874507904,\n",
       " 0.01696157455444336,\n",
       " 0.01188588049262762,\n",
       " 0.011069701053202152,\n",
       " 0.00906087551265955,\n",
       " 0.008440283127129078]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [0.0525, 0.0082, 0.0068, 0.0066, 0.0049, 0.0052, 0.0047]\n",
    "l2 = [0.0179, 0.0143, 0.0024, 0.0080, 0.0096, 0.0185, 0.0051]\n",
    "l3 = [0.0094, 0.0020, 9.3183e-04, 2.6615e-04, 3.0940e-04, 2.0069e-04, 2.5472e-04]\n",
    "l4 = [1.1707, 0.5699, 0.1792, 0.1660, 0.1199, 0.1372, 0.1152]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.DataFrame([l1,l2,l3,l4,data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns = ['SimpleCNN', 'ComplexCNN', 'DenseNet121', 'ResNet50', 'Xecption']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SimpleCNN</th>\n",
       "      <th>ComplexCNN</th>\n",
       "      <th>DenseNet121</th>\n",
       "      <th>ResNet50</th>\n",
       "      <th>Xecption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>1.1707</td>\n",
       "      <td>0.165947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.5699</td>\n",
       "      <td>0.031580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>0.016962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>0.011886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>0.011070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.1372</td>\n",
       "      <td>0.009061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.1152</td>\n",
       "      <td>0.008440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SimpleCNN  ComplexCNN  DenseNet121  ResNet50  Xecption\n",
       "0     0.0525      0.0179     0.009400    1.1707  0.165947\n",
       "1     0.0082      0.0143     0.002000    0.5699  0.031580\n",
       "2     0.0068      0.0024     0.000932    0.1792  0.016962\n",
       "3     0.0066      0.0080     0.000266    0.1660  0.011886\n",
       "4     0.0049      0.0096     0.000309    0.1199  0.011070\n",
       "5     0.0052      0.0185     0.000201    0.1372  0.009061\n",
       "6     0.0047      0.0051     0.000255    0.1152  0.008440"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f89d1773f10>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(\"white\")\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "plt.plot(df1.index, df1.SimpleCNN, \"o-\", ms=3,\n",
    "            color=\"r\", label='SimpleCNN')\n",
    "plt.plot(df1.index, df1.ComplexCNN, \"o-\", ms=3,\n",
    "            color=\"g\", label='ComplexCNN')\n",
    "plt.plot(df1.index, df1.DenseNet121, \"o-\", ms=3,\n",
    "            color=\"blue\", label='DenseNet121')\n",
    "plt.plot(df1.index, df1.ResNet50, \"o-\", ms=3,\n",
    "            color=\"orange\", label='ResNet50')\n",
    "plt.plot(df1.index, df1.Xecption, \"o-\", ms=3,\n",
    "            color=\"yellow\", label='Xception')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
